{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d20dfb9-e39a-45bb-93f5-f5e98c4e9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, sys\n",
    "import warnings\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "sys.path.append(\"..\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import psutil\n",
    "import gc\n",
    "import gym\n",
    "import dmc2gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from itertools import count\n",
    "from gym import spaces\n",
    "from torch.autograd import Variable\n",
    "#from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from src.networks import FeedForwardNet, FeedForwardNet_v2, EnvModel, FeedForwardNet_v2_dist\n",
    "from src.replay_buffer import Replay_buffer\n",
    "from src.utils import fanin_init, weights_init_normal, Average, freeze, unfreeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac3575-3cad-490c-bbb7-9dd527a89106",
   "metadata": {},
   "source": [
    "## Initialize environment and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e064e412-5bbf-4d9a-b2ed-6ebbb153e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkadiy/.local/lib/python3.8/site-packages/dmc2gym/wrappers.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dim = np.int(np.prod(s.shape))\n",
      "/home/arkadiy/.local/lib/python3.8/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/arkadiy/.local/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "lr = 0.0001\n",
    "hidden_size = 200\n",
    "model_hidden_size = 64\n",
    "max_episodes = 1000\n",
    "max_steps = 1000\n",
    "max_buffer = 100000\n",
    "device = 'cuda'\n",
    "use_pretrained_model = False\n",
    "domain_name = 'cartpole'\n",
    "task_name = 'balance'\n",
    "agent_name = f'{domain_name}_{task_name}_hs{model_hidden_size}'\n",
    "\n",
    "env = dmc2gym.make(domain_name=domain_name, task_name=task_name, seed=1)\n",
    "env.seed(2023)\n",
    "torch.manual_seed(2023)\n",
    "np.random.seed(2023)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "q_dim = 1 \n",
    "max_action = float(env.action_space.high[0])\n",
    "min_Val = torch.tensor(1e-7).float().to(device) # min value\n",
    "\n",
    "directory = './data/'\n",
    "model_directory = directory + 'models/'\n",
    "plot_directory = directory + 'plots/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb36a29-e02f-47ae-ab39-bb631b6f9a48",
   "metadata": {},
   "source": [
    "## Build solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4222c0cf-ac18-4ce1-8df9-829db516c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPModel(object):\n",
    "    def __init__(self, state_dim, action_dim, q_dim, hidden_size=32, model_hidden_size=300, lr=1e-3, batch_size=1, device='cuda'): \n",
    "        \n",
    "        self.device = device\n",
    "        self.q_dim = q_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_model_update_iteration = 0\n",
    "        self.update_iterations = 200\n",
    "        self.model_update_iterations = 200\n",
    "        \n",
    "        self.policy = FeedForwardNet_v2_dist(state_dim, q_dim, action_dim, hidden_size).to(self.device)\n",
    "        self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr)\n",
    "        \n",
    "        self.potential = FeedForwardNet(state_dim, action_dim, hidden_size).to(self.device)\n",
    "        self.potential_optimizer = torch.optim.Adam(self.potential.parameters(), lr)\n",
    "        \n",
    "        self.model = EnvModel(state_dim, action_dim, model_hidden_size*2, model_hidden_size).to(self.device)\n",
    "        self.model_optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.model_loss = nn.MSELoss()\n",
    "        \n",
    "        self.replay_buffer = Replay_buffer(max_size=1000000)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        q = torch.randn(1, self.q_dim).to(self.device)\n",
    "        state = Variable(torch.from_numpy(np.float32(state))).reshape(1, -1).to(self.device)\n",
    "        action = self.policy.act(state,q)\n",
    "        action = torch.clamp(action, -1, 1)\n",
    "        return action.cpu().data.numpy().flatten()\n",
    "    \n",
    "    def update(self, state):\n",
    "        ploss = []\n",
    "        floss = []\n",
    "        for it in range(self.update_iterations):\n",
    "            unfreeze(self.policy); freeze(self.potential); freeze(self.model) \n",
    "            \n",
    "            x, _, u, _, _ = self.replay_buffer.sample(self.batch_size)\n",
    "            state = torch.FloatTensor(x).to(self.device)\n",
    "            #action = torch.FloatTensor(u).reshape(self.batch_size, self.action_dim).to(self.device)\n",
    "            \n",
    "            #state =  Variable(torch.from_numpy(np.float32(state))).reshape(self.batch_size, self.state_dim).to(self.device)\n",
    "            q = torch.randn(self.batch_size, self.q_dim).to(self.device)\n",
    "            #action = self.policy(state,q)\n",
    "            action_means, action_log_stds, action_stds = self.policy(state,q)\n",
    "            with torch.no_grad():\n",
    "                actions = torch.normal(action_means, action_stds)\n",
    "                actions = torch.clamp(actions, -1, 1)\n",
    "            next_state, r, _ = self.model(state,actions)\n",
    "            log_prob = normal_log_density(actions, action_means, action_log_stds, action_stds)\n",
    "            \n",
    "            #print(\"!!!!!\", len(log_prob), r, len(-r.mean()*log_prob))\n",
    "            \n",
    "            #P_loss = -r.mean()*log_prob + self.potential(state).mean() - self.potential(next_state).mean()\n",
    "            P_loss = -(r*log_prob).mean() + self.potential(state).mean() - self.potential(next_state).mean()\n",
    "            self.policy_optimizer.zero_grad()\n",
    "            P_loss.backward()\n",
    "            self.policy_optimizer.step()\n",
    "            ploss.append(P_loss)\n",
    "            \n",
    "            freeze(self.policy); unfreeze(self.potential); freeze(self.model)\n",
    "            #x, _, _, _, _ = self.replay_buffer.sample(self.batch_size)\n",
    "            state = torch.FloatTensor(x).to(self.device)\n",
    "            q = torch.randn(self.batch_size, self.q_dim).to(self.device)\n",
    "            with torch.no_grad(): \n",
    "                action = self.policy.act(state,q)\n",
    "                action = torch.clamp(action, -1, 1)\n",
    "                next_state, _, _ = self.model(state,action)\n",
    "            f_loss = self.potential(state).mean() - self.potential(next_state).mean()\n",
    "            f_loss = -f_loss\n",
    "            self.potential_optimizer.zero_grad()\n",
    "            f_loss.backward() \n",
    "            self.potential_optimizer.step()\n",
    "            floss.append(f_loss)\n",
    "            \n",
    "        return action, ploss, floss\n",
    "            \n",
    "            \n",
    "    def env_update(self):\n",
    "        closses = []\n",
    "        mlosses = []\n",
    "        for it in range(self.model_update_iterations):\n",
    "            unfreeze(self.model);\n",
    "            x, y, u, r, d = self.replay_buffer.sample(self.batch_size)\n",
    "            state = torch.FloatTensor(x).to(self.device)\n",
    "            action = torch.FloatTensor(u).reshape(self.batch_size, self.action_dim).to(self.device)\n",
    "            next_state = torch.FloatTensor(y).to(self.device)\n",
    "            done = torch.FloatTensor(1-d).to(self.device)\n",
    "            reward = torch.FloatTensor(r).to(self.device)\n",
    "            \n",
    "            #action = action.reshape(self.batch_size, self.action_dim)\n",
    "            #action = action[:,None]\n",
    "            \n",
    "            state_, reward_, done_ = self.model(state, action)\n",
    "            loss_s = self.model_loss(state_, next_state)\n",
    "            loss_r = self.model_loss(reward_, reward)\n",
    "            loss_d = self.model_loss(done_, done)\n",
    "            \n",
    "            closses.append(loss_r)\n",
    "            mlosses.append(loss_s)\n",
    "\n",
    "            self.model_optimizer.zero_grad()\n",
    "            loss = loss_s+loss_r+loss_d\n",
    "            loss.backward()\n",
    "            self.model_optimizer.step()\n",
    "            self.num_model_update_iteration += 1\n",
    "        return closses, mlosses\n",
    "            \n",
    "    def evaluate(self, policy, env):\n",
    "        best_ep_r = 0\n",
    "        total_reward = 0\n",
    "        for i_episode in range(10):\n",
    "            state = env.reset()\n",
    "            ep_r = 0\n",
    "            timestep = 0\n",
    "            rwd_dyna = []\n",
    "            total_steps = 0\n",
    "            while True:\n",
    "            #for _ in range (10):\n",
    "                total_steps += 1\n",
    "                # env.render()\n",
    "                state = Variable(torch.from_numpy(np.float32(state))).reshape(1, self.state_dim).to(self.device)\n",
    "                q = torch.randn(1, self.q_dim).to(self.device)\n",
    "                #action = policy(state,q)\n",
    "                action = policy.act(state,q)\n",
    "                action = torch.clamp(action, -1, 1)\n",
    "                #a = torch.clamp(a, min=0, max=1) \n",
    "                #action = torch.clamp(action, -1, 1)   \n",
    "                s_, r, done, info = env.step(action.cpu().detach().numpy()[0])\n",
    "                ep_r += r\n",
    "                if done:\n",
    "                    break\n",
    "                state = s_\n",
    "            total_reward += ep_r\n",
    "            if ep_r > best_ep_r:\n",
    "                best_ep_r = ep_r\n",
    "        print('Total reward:', total_reward)\n",
    "        print('Best achieved reward:', best_ep_r)\n",
    "        return best_ep_r\n",
    "            \n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.policy.state_dict(), model_directory + 'policy.pth')\n",
    "        torch.save(self.potential.state_dict(), model_directory + 'potential.pth')\n",
    "        torch.save(self.model.state_dict(), model_directory + 'model.pth')\n",
    "        print(\"====================================\")\n",
    "        print(\"Model has been saved...\")\n",
    "        print(\"====================================\")\n",
    "\n",
    "    def load(self):\n",
    "        self.policy.load_state_dict(torch.load(model_directory + 'policy.pth'))\n",
    "        self.potential.load_state_dict(torch.load(model_directory + 'potential.pth'))\n",
    "        self.model.load_state_dict(torch.load(model_directory + 'model.pth'))\n",
    "        print(\"====================================\")\n",
    "        print(\"models has been loaded...\")\n",
    "        print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "764bdba4-0161-4805-b529-f4321edbf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained_model:\n",
    "    agent = LPModel(state_dim, action_dim, q_dim, hidden_size, model_hidden_size, lr, batch_size, device)\n",
    "    model_name = agent_name+'_model.pt'\n",
    "    policy_name = agent_name+'_best_policy.pt'\n",
    "    agent.model.load_state_dict(torch.load(f'{model_directory}{model_name}'))\n",
    "    train_worldmodel = False\n",
    "    freeze(agent.model) \n",
    "else:\n",
    "    agent = LPModel(state_dim, action_dim, q_dim, hidden_size, model_hidden_size, lr, batch_size, device)\n",
    "    train_worldmodel = True \n",
    "    model_name = agent_name+'_model.pt'\n",
    "    policy_name = agent_name+'_best_policy.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eab936-f86a-4073-a753-91a9dd227631",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ad08c6-7f30-4c01-9d59-2894524eca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "ploss = []\n",
    "dloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02838af5-1360-4990-a8db-dae2a5666de5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03131103515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c00f7b62929480c84105bb442f41835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkadiy/.local/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/tmp/ipykernel_15058/2603271396.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  agent.replay_buffer.push((state, next_state, action, reward, np.float(done)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total T:1000 Episode: \t0 Total Reward: \t356.22 Ploss: \t2.18161940574646 Floss: \t-4.558348655700684 Closs: \t0.025047902017831802 Mloss: \t0.4390157461166382\n",
      "Ploss 2.18161940574646\n",
      "Floss -4.558348655700684\n",
      "Total reward: 2318.3258066876465\n",
      "Best achieved reward: 256.4334117333137\n",
      "--------------------------------\n",
      "Total T:2000 Episode: \t1 Total Reward: \t230.54 Ploss: \t4.25661563873291 Floss: \t-1.6884770393371582 Closs: \t0.0037625699769705534 Mloss: \t0.007802044041454792\n",
      "Total T:3000 Episode: \t2 Total Reward: \t203.02 Ploss: \t1.8455822467803955 Floss: \t-1.5307960510253906 Closs: \t0.0013598456280305982 Mloss: \t0.0059881070628762245\n",
      "Total T:4000 Episode: \t3 Total Reward: \t232.58 Ploss: \t0.3131258189678192 Floss: \t0.007557353936135769 Closs: \t0.0007738943095318973 Mloss: \t0.0019832889083772898\n",
      "Total T:5000 Episode: \t4 Total Reward: \t301.75 Ploss: \t0.4326726198196411 Floss: \t-0.11866489052772522 Closs: \t0.0006468840292654932 Mloss: \t0.001506672939285636\n",
      "Total T:6000 Episode: \t5 Total Reward: \t198.21 Ploss: \t0.42224422097206116 Floss: \t-0.11697115004062653 Closs: \t0.0005731845158152282 Mloss: \t0.0016228759195655584\n",
      "Total T:7000 Episode: \t6 Total Reward: \t241.97 Ploss: \t0.7778783440589905 Floss: \t-0.4869554936885834 Closs: \t0.0004663181316573173 Mloss: \t0.0017135245725512505\n",
      "Total T:8000 Episode: \t7 Total Reward: \t362.81 Ploss: \t0.4205251634120941 Floss: \t-0.10273328423500061 Closs: \t0.0004075795295648277 Mloss: \t0.001504318555817008\n",
      "Total T:9000 Episode: \t8 Total Reward: \t270.83 Ploss: \t0.3843834102153778 Floss: \t-0.07375331968069077 Closs: \t0.0003332114138174802 Mloss: \t0.0013267099857330322\n",
      "Total T:10000 Episode: \t9 Total Reward: \t260.11 Ploss: \t0.4313789904117584 Floss: \t-0.12583258748054504 Closs: \t0.0003093925479333848 Mloss: \t0.00121353380382061\n",
      "Total T:11000 Episode: \t10 Total Reward: \t375.84 Ploss: \t0.36963874101638794 Floss: \t-0.05640985444188118 Closs: \t0.00026862884988076985 Mloss: \t0.0011227623326703906\n",
      "Total T:12000 Episode: \t11 Total Reward: \t336.44 Ploss: \t0.4017963409423828 Floss: \t-0.07850973308086395 Closs: \t0.00025047612143680453 Mloss: \t0.0010446006199344993\n",
      "Total T:13000 Episode: \t12 Total Reward: \t372.73 Ploss: \t0.3465205430984497 Floss: \t-0.007888211868703365 Closs: \t0.0002299872721778229 Mloss: \t0.0010005972580984235\n",
      "Total T:14000 Episode: \t13 Total Reward: \t248.18 Ploss: \t0.2736099064350128 Floss: \t0.0625554770231247 Closs: \t0.0002188783255405724 Mloss: \t0.0008921471307985485\n",
      "Total T:15000 Episode: \t14 Total Reward: \t331.68 Ploss: \t0.4270557761192322 Floss: \t-0.0994354858994484 Closs: \t0.00020413589663803577 Mloss: \t0.0008340974454768002\n",
      "Total T:16000 Episode: \t15 Total Reward: \t275.16 Ploss: \t0.37436336278915405 Floss: \t-0.04550928995013237 Closs: \t0.00020318561291787773 Mloss: \t0.0008525055600330234\n",
      "Total T:17000 Episode: \t16 Total Reward: \t377.06 Ploss: \t0.44658103585243225 Floss: \t-0.11915834993124008 Closs: \t0.00020077491353731602 Mloss: \t0.0008287045639008284\n",
      "Total T:18000 Episode: \t17 Total Reward: \t411.08 Ploss: \t0.29119980335235596 Floss: \t0.05652204528450966 Closs: \t0.0002113628579536453 Mloss: \t0.0007835632422938943\n",
      "Total T:19000 Episode: \t18 Total Reward: \t252.40 Ploss: \t0.3550437390804291 Floss: \t-0.0242886021733284 Closs: \t0.0001930134167196229 Mloss: \t0.0007583093247376382\n",
      "Total T:20000 Episode: \t19 Total Reward: \t298.79 Ploss: \t0.499042272567749 Floss: \t-0.15778596699237823 Closs: \t0.0001851788256317377 Mloss: \t0.0007322963792830706\n",
      "Total T:21000 Episode: \t20 Total Reward: \t438.65 Ploss: \t0.4972051978111267 Floss: \t-0.15589399635791779 Closs: \t0.0001785933563951403 Mloss: \t0.0006841736612841487\n",
      "Total T:22000 Episode: \t21 Total Reward: \t335.04 Ploss: \t0.3993929326534271 Floss: \t-0.06012241542339325 Closs: \t0.0001818048913264647 Mloss: \t0.0006799690891057253\n",
      "Total T:23000 Episode: \t22 Total Reward: \t427.58 Ploss: \t0.4516725540161133 Floss: \t-0.09614280611276627 Closs: \t0.0001678213448030874 Mloss: \t0.0006681042141281068\n",
      "Total T:24000 Episode: \t23 Total Reward: \t289.38 Ploss: \t0.4390876591205597 Floss: \t-0.08514460176229477 Closs: \t0.00016436136502306908 Mloss: \t0.0006550841499119997\n",
      "Total T:25000 Episode: \t24 Total Reward: \t284.01 Ploss: \t0.5795841813087463 Floss: \t-0.23202501237392426 Closs: \t0.00016138260252773762 Mloss: \t0.0006528254598379135\n",
      "Total T:26000 Episode: \t25 Total Reward: \t287.84 Ploss: \t0.4848078191280365 Floss: \t-0.15601865947246552 Closs: \t0.00014289916725829244 Mloss: \t0.0006399768171831965\n",
      "Total T:27000 Episode: \t26 Total Reward: \t307.25 Ploss: \t0.5870750546455383 Floss: \t-0.24201899766921997 Closs: \t0.00018275331240147352 Mloss: \t0.0006091719260439277\n",
      "Total T:28000 Episode: \t27 Total Reward: \t330.66 Ploss: \t0.5020703077316284 Floss: \t-0.16534951329231262 Closs: \t0.00014397608174476773 Mloss: \t0.0005761643988080323\n",
      "Total T:29000 Episode: \t28 Total Reward: \t316.49 Ploss: \t0.5628340244293213 Floss: \t-0.21241046488285065 Closs: \t0.00013587396824732423 Mloss: \t0.0005573778762482107\n",
      "Total T:30000 Episode: \t29 Total Reward: \t323.06 Ploss: \t0.8739066123962402 Floss: \t-0.5323877334594727 Closs: \t0.00013113477325532585 Mloss: \t0.0005463958950713277\n",
      "Total T:31000 Episode: \t30 Total Reward: \t369.49 Ploss: \t0.24478834867477417 Floss: \t0.0714896023273468 Closs: \t0.00013043996295891702 Mloss: \t0.0005431428435258567\n",
      "Total T:32000 Episode: \t31 Total Reward: \t377.78 Ploss: \t1.2923836708068848 Floss: \t-0.9603756666183472 Closs: \t0.00012887474440503865 Mloss: \t0.0005212649703025818\n",
      "Total T:33000 Episode: \t32 Total Reward: \t295.81 Ploss: \t0.9014381170272827 Floss: \t-0.5760104060173035 Closs: \t0.00013074300659354776 Mloss: \t0.0004887433024123311\n",
      "Total T:34000 Episode: \t33 Total Reward: \t294.08 Ploss: \t0.38292890787124634 Floss: \t-0.043263547122478485 Closs: \t0.00011825139517895877 Mloss: \t0.0005034004570916295\n",
      "Total T:35000 Episode: \t34 Total Reward: \t353.17 Ploss: \t1.898576021194458 Floss: \t-1.5582040548324585 Closs: \t0.00014370385906659067 Mloss: \t0.000508877623360604\n",
      "Total T:36000 Episode: \t35 Total Reward: \t255.42 Ploss: \t0.20781683921813965 Floss: \t0.13968536257743835 Closs: \t0.0001094419858418405 Mloss: \t0.0004886295064352453\n",
      "Total T:37000 Episode: \t36 Total Reward: \t400.66 Ploss: \t1.2342439889907837 Floss: \t-0.8906089067459106 Closs: \t0.00010919416672550142 Mloss: \t0.0004671691276598722\n",
      "Total T:38000 Episode: \t37 Total Reward: \t423.07 Ploss: \t1.7678608894348145 Floss: \t-1.4132609367370605 Closs: \t0.00011646701750578359 Mloss: \t0.0004586707800626755\n",
      "Total T:39000 Episode: \t38 Total Reward: \t303.77 Ploss: \t1.5513404607772827 Floss: \t-1.1680445671081543 Closs: \t0.00012244611571077257 Mloss: \t0.0004916096804663539\n",
      "Total T:40000 Episode: \t39 Total Reward: \t412.25 Ploss: \t0.6596740484237671 Floss: \t-0.38338544964790344 Closs: \t0.00011357099720044062 Mloss: \t0.0004797604924533516\n",
      "Total T:41000 Episode: \t40 Total Reward: \t333.10 Ploss: \t2.562091112136841 Floss: \t-2.227426528930664 Closs: \t0.00010855404252652079 Mloss: \t0.0004457524628378451\n",
      "Total T:42000 Episode: \t41 Total Reward: \t274.87 Ploss: \t0.4600457549095154 Floss: \t-0.18590208888053894 Closs: \t0.00011004298721672967 Mloss: \t0.000473055086331442\n",
      "Total T:43000 Episode: \t42 Total Reward: \t369.98 Ploss: \t3.329714059829712 Floss: \t-3.042046546936035 Closs: \t0.00010747618944151327 Mloss: \t0.00045476880040951073\n",
      "Total T:44000 Episode: \t43 Total Reward: \t255.23 Ploss: \t1.150718331336975 Floss: \t-0.94374018907547 Closs: \t0.00010685369488783181 Mloss: \t0.00044952149619348347\n",
      "Total T:45000 Episode: \t44 Total Reward: \t314.04 Ploss: \t1.700631022453308 Floss: \t-1.335121989250183 Closs: \t0.0001163553970400244 Mloss: \t0.00044036528561264277\n",
      "Total T:46000 Episode: \t45 Total Reward: \t384.53 Ploss: \t3.4931838512420654 Floss: \t-3.2419118881225586 Closs: \t9.371111809741706e-05 Mloss: \t0.00043438392458483577\n",
      "Total T:47000 Episode: \t46 Total Reward: \t402.56 Ploss: \t1.098294973373413 Floss: \t-0.8890215754508972 Closs: \t0.00011280471517238766 Mloss: \t0.00045069665065966547\n",
      "Total T:48000 Episode: \t47 Total Reward: \t297.60 Ploss: \t0.5231775045394897 Floss: \t-0.305397629737854 Closs: \t0.0001100202280213125 Mloss: \t0.00044471907312981784\n",
      "Total T:49000 Episode: \t48 Total Reward: \t423.98 Ploss: \t0.33191436529159546 Floss: \t-0.08126464486122131 Closs: \t8.717662421986461e-05 Mloss: \t0.00039272071444429457\n",
      "Total T:50000 Episode: \t49 Total Reward: \t350.79 Ploss: \t1.8348486423492432 Floss: \t-1.7264279127120972 Closs: \t0.00010323950118618086 Mloss: \t0.00041037111077457666\n",
      "Total T:51000 Episode: \t50 Total Reward: \t299.46 Ploss: \t0.7270849347114563 Floss: \t-0.4154254198074341 Closs: \t9.80820186669007e-05 Mloss: \t0.00037555754533968866\n",
      "Ploss 0.7270849347114563\n",
      "Floss -0.4154254198074341\n",
      "Total reward: 3277.0537447431625\n",
      "Best achieved reward: 406.6362979512756\n",
      "--------------------------------\n",
      "Total T:52000 Episode: \t51 Total Reward: \t259.93 Ploss: \t4.780051231384277 Floss: \t-4.4948835372924805 Closs: \t9.733180922921747e-05 Mloss: \t0.00038232869701460004\n",
      "Total T:53000 Episode: \t52 Total Reward: \t391.54 Ploss: \t0.842625081539154 Floss: \t-0.5505548119544983 Closs: \t9.18345685931854e-05 Mloss: \t0.00038819541805423796\n",
      "Total T:54000 Episode: \t53 Total Reward: \t390.68 Ploss: \t3.9467077255249023 Floss: \t-3.7786309719085693 Closs: \t0.00011034452472813427 Mloss: \t0.0003885739133693278\n",
      "Total T:55000 Episode: \t54 Total Reward: \t349.84 Ploss: \t-0.762191116809845 Floss: \t1.089877963066101 Closs: \t8.75931145856157e-05 Mloss: \t0.0003724903508555144\n",
      "Total T:56000 Episode: \t55 Total Reward: \t437.93 Ploss: \t2.905015230178833 Floss: \t-2.6578643321990967 Closs: \t8.281151531264186e-05 Mloss: \t0.0003669380384963006\n",
      "Total T:57000 Episode: \t56 Total Reward: \t219.96 Ploss: \t7.618341445922852 Floss: \t-7.124675750732422 Closs: \t9.005179163068533e-05 Mloss: \t0.0003750473842956126\n",
      "Total T:58000 Episode: \t57 Total Reward: \t204.56 Ploss: \t7.487425804138184 Floss: \t-7.0882720947265625 Closs: \t9.153903374681249e-05 Mloss: \t0.00038363345083780587\n",
      "Total T:59000 Episode: \t58 Total Reward: \t273.58 Ploss: \t4.4894280433654785 Floss: \t-4.326984882354736 Closs: \t8.21192079456523e-05 Mloss: \t0.0003602110082283616\n",
      "Total T:60000 Episode: \t59 Total Reward: \t407.48 Ploss: \t6.198027610778809 Floss: \t-5.9643707275390625 Closs: \t9.011587098939344e-05 Mloss: \t0.0003657427441794425\n",
      "Total T:61000 Episode: \t60 Total Reward: \t297.74 Ploss: \t7.170224666595459 Floss: \t-6.922170639038086 Closs: \t8.754654845688492e-05 Mloss: \t0.00035676659899763763\n",
      "Total T:62000 Episode: \t61 Total Reward: \t308.28 Ploss: \t5.600679874420166 Floss: \t-5.323925495147705 Closs: \t8.554186206310987e-05 Mloss: \t0.0003412655205465853\n",
      "Total T:63000 Episode: \t62 Total Reward: \t289.89 Ploss: \t7.730857849121094 Floss: \t-7.61718225479126 Closs: \t9.300707461079583e-05 Mloss: \t0.0003571431734599173\n",
      "Total T:64000 Episode: \t63 Total Reward: \t294.38 Ploss: \t1.059381127357483 Floss: \t-0.7206506133079529 Closs: \t7.733747770544142e-05 Mloss: \t0.0003676430496852845\n",
      "Total T:65000 Episode: \t64 Total Reward: \t353.55 Ploss: \t-0.8146349787712097 Floss: \t0.7562048435211182 Closs: \t7.557321805506945e-05 Mloss: \t0.00034977341420017183\n",
      "Total T:66000 Episode: \t65 Total Reward: \t483.40 Ploss: \t-2.153856039047241 Floss: \t2.2078857421875 Closs: \t9.04554981389083e-05 Mloss: \t0.00035217858385294676\n",
      "Total T:67000 Episode: \t66 Total Reward: \t295.82 Ploss: \t6.656575679779053 Floss: \t-6.458453178405762 Closs: \t7.518078928114846e-05 Mloss: \t0.0003304739948362112\n",
      "Total T:68000 Episode: \t67 Total Reward: \t395.35 Ploss: \t5.707361698150635 Floss: \t-5.525462627410889 Closs: \t8.6508909589611e-05 Mloss: \t0.00034051897819153965\n",
      "Total T:69000 Episode: \t68 Total Reward: \t347.78 Ploss: \t-1.6532080173492432 Floss: \t1.9067736864089966 Closs: \t7.239410479087383e-05 Mloss: \t0.0003440905420575291\n",
      "Total T:70000 Episode: \t69 Total Reward: \t211.19 Ploss: \t6.804722785949707 Floss: \t-6.580551624298096 Closs: \t7.543862011516467e-05 Mloss: \t0.00032890646252781153\n",
      "Total T:71000 Episode: \t70 Total Reward: \t331.04 Ploss: \t14.001911163330078 Floss: \t-13.64707088470459 Closs: \t8.255404100054875e-05 Mloss: \t0.00032377729075960815\n",
      "Total T:72000 Episode: \t71 Total Reward: \t467.87 Ploss: \t12.719460487365723 Floss: \t-12.438297271728516 Closs: \t8.329815318575129e-05 Mloss: \t0.00032556927180849016\n",
      "Total T:73000 Episode: \t72 Total Reward: \t431.22 Ploss: \t3.553417921066284 Floss: \t-3.1496057510375977 Closs: \t7.876411837060004e-05 Mloss: \t0.00031289851176552474\n",
      "Total T:74000 Episode: \t73 Total Reward: \t475.05 Ploss: \t-1.9362280368804932 Floss: \t1.752073884010315 Closs: \t6.232249870663509e-05 Mloss: \t0.00031446365755982697\n",
      "Total T:75000 Episode: \t74 Total Reward: \t349.89 Ploss: \t7.162938117980957 Floss: \t-6.962374210357666 Closs: \t7.699109119130298e-05 Mloss: \t0.0003337489615660161\n",
      "Total T:76000 Episode: \t75 Total Reward: \t308.90 Ploss: \t6.903264999389648 Floss: \t-6.712827205657959 Closs: \t8.669525414006785e-05 Mloss: \t0.0003082640760112554\n",
      "Total T:77000 Episode: \t76 Total Reward: \t359.60 Ploss: \t0.6605749130249023 Floss: \t-0.46559691429138184 Closs: \t6.532513361889869e-05 Mloss: \t0.00031047171796672046\n",
      "Total T:78000 Episode: \t77 Total Reward: \t338.37 Ploss: \t11.813015937805176 Floss: \t-11.553353309631348 Closs: \t7.135402847779915e-05 Mloss: \t0.0003022847231477499\n",
      "Total T:79000 Episode: \t78 Total Reward: \t371.93 Ploss: \t1.1245166063308716 Floss: \t-1.082131266593933 Closs: \t7.040060154395178e-05 Mloss: \t0.00030345330014824867\n",
      "Total T:80000 Episode: \t79 Total Reward: \t407.69 Ploss: \t-3.022876024246216 Floss: \t3.3627476692199707 Closs: \t6.914790719747543e-05 Mloss: \t0.00029301861650310457\n",
      "Total T:81000 Episode: \t80 Total Reward: \t367.34 Ploss: \t6.09800386428833 Floss: \t-5.700170993804932 Closs: \t6.898064748384058e-05 Mloss: \t0.0003139692125841975\n",
      "Total T:82000 Episode: \t81 Total Reward: \t363.55 Ploss: \t3.215501546859741 Floss: \t-3.037747621536255 Closs: \t6.612165452679619e-05 Mloss: \t0.00030511277145706117\n",
      "Total T:83000 Episode: \t82 Total Reward: \t354.72 Ploss: \t3.465006113052368 Floss: \t-3.338996410369873 Closs: \t6.349653995130211e-05 Mloss: \t0.00029639987042173743\n",
      "Total T:84000 Episode: \t83 Total Reward: \t294.90 Ploss: \t-7.220274448394775 Floss: \t7.328591346740723 Closs: \t6.954514537937939e-05 Mloss: \t0.00028198881773278117\n",
      "Total T:85000 Episode: \t84 Total Reward: \t377.21 Ploss: \t-0.9572668075561523 Floss: \t1.1672558784484863 Closs: \t6.552983541041613e-05 Mloss: \t0.000290590338408947\n",
      "Total T:86000 Episode: \t85 Total Reward: \t413.78 Ploss: \t21.923734664916992 Floss: \t-21.5186710357666 Closs: \t7.00823002262041e-05 Mloss: \t0.000284729030681774\n",
      "Total T:87000 Episode: \t86 Total Reward: \t349.83 Ploss: \t11.6942720413208 Floss: \t-11.643820762634277 Closs: \t6.212989683263004e-05 Mloss: \t0.00027476734248921275\n",
      "Total T:88000 Episode: \t87 Total Reward: \t257.39 Ploss: \t4.571930885314941 Floss: \t-4.234416484832764 Closs: \t6.606603710679337e-05 Mloss: \t0.0002795100735966116\n",
      "Total T:89000 Episode: \t88 Total Reward: \t430.47 Ploss: \t9.542365074157715 Floss: \t-9.0831298828125 Closs: \t6.834461964899674e-05 Mloss: \t0.0002765593526419252\n",
      "Total T:90000 Episode: \t89 Total Reward: \t339.42 Ploss: \t3.27392315864563 Floss: \t-3.202944278717041 Closs: \t6.014503014739603e-05 Mloss: \t0.0002677035517990589\n",
      "Total T:91000 Episode: \t90 Total Reward: \t347.56 Ploss: \t16.61642837524414 Floss: \t-16.487098693847656 Closs: \t6.0814189055236056e-05 Mloss: \t0.00026800448540598154\n",
      "Total T:92000 Episode: \t91 Total Reward: \t387.79 Ploss: \t15.229320526123047 Floss: \t-14.879904747009277 Closs: \t6.014319296809845e-05 Mloss: \t0.0002889784809667617\n",
      "Total T:93000 Episode: \t92 Total Reward: \t397.09 Ploss: \t13.24688720703125 Floss: \t-13.154397010803223 Closs: \t6.284048868110403e-05 Mloss: \t0.0002766565594356507\n",
      "Total T:94000 Episode: \t93 Total Reward: \t398.83 Ploss: \t19.178125381469727 Floss: \t-18.933927536010742 Closs: \t6.156998279038817e-05 Mloss: \t0.0002696932351682335\n",
      "Total T:95000 Episode: \t94 Total Reward: \t431.15 Ploss: \t14.401115417480469 Floss: \t-14.077892303466797 Closs: \t6.830418715253472e-05 Mloss: \t0.00026820439961738884\n",
      "Total T:96000 Episode: \t95 Total Reward: \t446.33 Ploss: \t0.18651854991912842 Floss: \t-0.2100878804922104 Closs: \t4.877035826211795e-05 Mloss: \t0.00029578752582892776\n",
      "Total T:97000 Episode: \t96 Total Reward: \t358.48 Ploss: \t13.017374992370605 Floss: \t-12.906805992126465 Closs: \t6.63332175463438e-05 Mloss: \t0.0002705286897253245\n",
      "Total T:98000 Episode: \t97 Total Reward: \t333.50 Ploss: \t29.486522674560547 Floss: \t-29.087814331054688 Closs: \t5.8717119827633724e-05 Mloss: \t0.00029025383992120624\n",
      "Total T:99000 Episode: \t98 Total Reward: \t391.82 Ploss: \t18.911344528198242 Floss: \t-18.9605655670166 Closs: \t5.729236363549717e-05 Mloss: \t0.00027328982832841575\n",
      "Total T:100000 Episode: \t99 Total Reward: \t491.03 Ploss: \t39.934104919433594 Floss: \t-40.2833137512207 Closs: \t5.213221811573021e-05 Mloss: \t0.0002564570459071547\n",
      "Total T:101000 Episode: \t100 Total Reward: \t401.80 Ploss: \t14.219804763793945 Floss: \t-14.249777793884277 Closs: \t6.641882646363229e-05 Mloss: \t0.00025402320898137987\n",
      "Ploss 14.219804763793945\n",
      "Floss -14.249777793884277\n",
      "Total reward: 4205.120186505111\n",
      "Best achieved reward: 530.7344110407093\n",
      "--------------------------------\n",
      "Total T:102000 Episode: \t101 Total Reward: \t453.53 Ploss: \t17.489030838012695 Floss: \t-17.59536361694336 Closs: \t5.2507406508084387e-05 Mloss: \t0.0002489197358954698\n",
      "Total T:103000 Episode: \t102 Total Reward: \t333.67 Ploss: \t8.725983619689941 Floss: \t-8.333847045898438 Closs: \t5.451103061204776e-05 Mloss: \t0.0002642725594341755\n",
      "Total T:104000 Episode: \t103 Total Reward: \t357.27 Ploss: \t-5.118203163146973 Floss: \t4.775563716888428 Closs: \t6.191048305481672e-05 Mloss: \t0.00025361881125718355\n",
      "Total T:105000 Episode: \t104 Total Reward: \t330.25 Ploss: \t40.53236770629883 Floss: \t-40.00092697143555 Closs: \t5.4843716497998685e-05 Mloss: \t0.00025002285838127136\n",
      "Total T:106000 Episode: \t105 Total Reward: \t411.24 Ploss: \t31.53253746032715 Floss: \t-30.997020721435547 Closs: \t5.7860499509843066e-05 Mloss: \t0.00023933184274937958\n",
      "Total T:107000 Episode: \t106 Total Reward: \t316.45 Ploss: \t-15.0848970413208 Floss: \t15.289931297302246 Closs: \t5.353726010071114e-05 Mloss: \t0.00025348112103529274\n",
      "Total T:108000 Episode: \t107 Total Reward: \t310.98 Ploss: \t-23.12517547607422 Floss: \t23.122323989868164 Closs: \t5.129033888806589e-05 Mloss: \t0.00026742322370409966\n",
      "Total T:109000 Episode: \t108 Total Reward: \t366.43 Ploss: \t23.1131591796875 Floss: \t-23.541751861572266 Closs: \t5.678888919646852e-05 Mloss: \t0.00027004469302482903\n",
      "Total T:110000 Episode: \t109 Total Reward: \t329.24 Ploss: \t15.83447265625 Floss: \t-15.418837547302246 Closs: \t5.3387491789180785e-05 Mloss: \t0.0002626308414619416\n",
      "Total T:111000 Episode: \t110 Total Reward: \t290.66 Ploss: \t16.477386474609375 Floss: \t-16.734682083129883 Closs: \t5.210316157899797e-05 Mloss: \t0.0002453091728966683\n",
      "Total T:112000 Episode: \t111 Total Reward: \t389.65 Ploss: \t19.67900848388672 Floss: \t-19.777034759521484 Closs: \t5.023058838560246e-05 Mloss: \t0.0002445206046104431\n",
      "Total T:113000 Episode: \t112 Total Reward: \t300.31 Ploss: \t41.150638580322266 Floss: \t-41.65315246582031 Closs: \t5.06351025251206e-05 Mloss: \t0.00024396470689680427\n",
      "Total T:114000 Episode: \t113 Total Reward: \t425.73 Ploss: \t45.56356430053711 Floss: \t-45.43815231323242 Closs: \t5.922379932599142e-05 Mloss: \t0.00024138763546943665\n",
      "Total T:115000 Episode: \t114 Total Reward: \t509.09 Ploss: \t57.07320022583008 Floss: \t-57.06507110595703 Closs: \t4.845863441005349e-05 Mloss: \t0.00026096083456650376\n",
      "Total T:116000 Episode: \t115 Total Reward: \t337.08 Ploss: \t27.898832321166992 Floss: \t-28.22762107849121 Closs: \t5.0475158786866814e-05 Mloss: \t0.00023400288773700595\n",
      "Total T:117000 Episode: \t116 Total Reward: \t298.37 Ploss: \t38.94866943359375 Floss: \t-39.21603012084961 Closs: \t5.323020741343498e-05 Mloss: \t0.00022835134586784989\n",
      "Total T:118000 Episode: \t117 Total Reward: \t449.69 Ploss: \t32.82698059082031 Floss: \t-32.84577941894531 Closs: \t5.8930760133080184e-05 Mloss: \t0.00024250366550404578\n",
      "Total T:119000 Episode: \t118 Total Reward: \t363.08 Ploss: \t-5.745707988739014 Floss: \t6.106020450592041 Closs: \t4.327556598582305e-05 Mloss: \t0.00024397445668000728\n",
      "Total T:120000 Episode: \t119 Total Reward: \t365.67 Ploss: \t0.6312597393989563 Floss: \t-0.6365087628364563 Closs: \t4.753251050715335e-05 Mloss: \t0.0002332266594748944\n",
      "Total T:121000 Episode: \t120 Total Reward: \t539.01 Ploss: \t17.045146942138672 Floss: \t-17.159101486206055 Closs: \t5.204443368711509e-05 Mloss: \t0.00023906314163468778\n",
      "Total T:122000 Episode: \t121 Total Reward: \t394.56 Ploss: \t41.80093765258789 Floss: \t-42.09612274169922 Closs: \t4.96403627039399e-05 Mloss: \t0.00023945893917698413\n",
      "Total T:123000 Episode: \t122 Total Reward: \t313.41 Ploss: \t8.684511184692383 Floss: \t-8.834853172302246 Closs: \t4.6164252125890926e-05 Mloss: \t0.00022308123880065978\n",
      "Total T:124000 Episode: \t123 Total Reward: \t419.36 Ploss: \t47.96572494506836 Floss: \t-48.007240295410156 Closs: \t4.503363015828654e-05 Mloss: \t0.0002558920532464981\n",
      "Total T:125000 Episode: \t124 Total Reward: \t357.23 Ploss: \t39.302940368652344 Floss: \t-39.43803024291992 Closs: \t5.1175662520108745e-05 Mloss: \t0.00023140601115301251\n",
      "Total T:126000 Episode: \t125 Total Reward: \t457.60 Ploss: \t-21.7830753326416 Floss: \t21.28251838684082 Closs: \t5.251693801255897e-05 Mloss: \t0.0002337622718187049\n",
      "Total T:127000 Episode: \t126 Total Reward: \t470.05 Ploss: \t-14.733592987060547 Floss: \t15.798236846923828 Closs: \t4.936107143294066e-05 Mloss: \t0.00023862742818892002\n",
      "Total T:128000 Episode: \t127 Total Reward: \t543.41 Ploss: \t60.82400894165039 Floss: \t-61.83571243286133 Closs: \t4.931783041683957e-05 Mloss: \t0.00023120928381104022\n",
      "Total T:129000 Episode: \t128 Total Reward: \t371.64 Ploss: \t30.23173713684082 Floss: \t-30.577762603759766 Closs: \t4.3970234401058406e-05 Mloss: \t0.00023310727556236088\n",
      "Total T:130000 Episode: \t129 Total Reward: \t343.69 Ploss: \t58.936649322509766 Floss: \t-58.68670654296875 Closs: \t5.062507261754945e-05 Mloss: \t0.00023863135720603168\n",
      "Total T:131000 Episode: \t130 Total Reward: \t409.91 Ploss: \t52.59342575073242 Floss: \t-52.3493537902832 Closs: \t4.6916455175960436e-05 Mloss: \t0.00023861842055339366\n",
      "Total T:132000 Episode: \t131 Total Reward: \t394.82 Ploss: \t41.20277404785156 Floss: \t-40.97525405883789 Closs: \t3.874559479299933e-05 Mloss: \t0.0002319079067092389\n",
      "Total T:133000 Episode: \t132 Total Reward: \t328.63 Ploss: \t22.860273361206055 Floss: \t-22.825292587280273 Closs: \t4.752221502712928e-05 Mloss: \t0.0002232770639238879\n",
      "Total T:134000 Episode: \t133 Total Reward: \t479.22 Ploss: \t-0.364570289850235 Floss: \t0.3337499797344208 Closs: \t4.449941116035916e-05 Mloss: \t0.000212230283068493\n",
      "Total T:135000 Episode: \t134 Total Reward: \t534.31 Ploss: \t19.04572296142578 Floss: \t-20.43270492553711 Closs: \t5.032501940149814e-05 Mloss: \t0.000217176740989089\n",
      "Total T:136000 Episode: \t135 Total Reward: \t363.13 Ploss: \t58.31558609008789 Floss: \t-58.224578857421875 Closs: \t4.290952711016871e-05 Mloss: \t0.00021457952971104532\n",
      "Total T:137000 Episode: \t136 Total Reward: \t308.69 Ploss: \t42.794227600097656 Floss: \t-42.80500030517578 Closs: \t4.5318582124309614e-05 Mloss: \t0.00022168077703099698\n",
      "Total T:138000 Episode: \t137 Total Reward: \t352.17 Ploss: \t20.253496170043945 Floss: \t-20.028026580810547 Closs: \t4.458940384211019e-05 Mloss: \t0.00021706896950490773\n",
      "Total T:139000 Episode: \t138 Total Reward: \t420.12 Ploss: \t9.593193054199219 Floss: \t-9.700429916381836 Closs: \t5.223626794759184e-05 Mloss: \t0.0002279735927004367\n",
      "Total T:140000 Episode: \t139 Total Reward: \t481.01 Ploss: \t-48.05393600463867 Floss: \t49.04543685913086 Closs: \t4.342416286817752e-05 Mloss: \t0.0002198056608904153\n",
      "Total T:141000 Episode: \t140 Total Reward: \t465.07 Ploss: \t43.31170654296875 Floss: \t-43.92170715332031 Closs: \t3.6963425372960046e-05 Mloss: \t0.00020823066006414592\n",
      "Total T:142000 Episode: \t141 Total Reward: \t352.83 Ploss: \t56.529052734375 Floss: \t-55.83827209472656 Closs: \t4.6008564822841436e-05 Mloss: \t0.00021430208289530128\n",
      "Total T:143000 Episode: \t142 Total Reward: \t309.37 Ploss: \t-5.774628639221191 Floss: \t6.377275466918945 Closs: \t4.382748011266813e-05 Mloss: \t0.00020264943304937333\n",
      "Total T:144000 Episode: \t143 Total Reward: \t247.30 Ploss: \t43.02961730957031 Floss: \t-43.226131439208984 Closs: \t4.522562448983081e-05 Mloss: \t0.0002121092693414539\n",
      "Total T:145000 Episode: \t144 Total Reward: \t297.97 Ploss: \t8.716903686523438 Floss: \t-9.869462966918945 Closs: \t4.1799885366344824e-05 Mloss: \t0.00022389038349501789\n",
      "Total T:146000 Episode: \t145 Total Reward: \t313.54 Ploss: \t-28.299100875854492 Floss: \t29.555585861206055 Closs: \t4.1478229832137004e-05 Mloss: \t0.00022813714167568833\n",
      "Total T:147000 Episode: \t146 Total Reward: \t330.51 Ploss: \t10.139579772949219 Floss: \t-10.656415939331055 Closs: \t4.5653083361685276e-05 Mloss: \t0.0002031765616266057\n",
      "Total T:148000 Episode: \t147 Total Reward: \t428.64 Ploss: \t34.32608413696289 Floss: \t-34.417442321777344 Closs: \t4.2778778151841834e-05 Mloss: \t0.00022419611923396587\n",
      "Total T:149000 Episode: \t148 Total Reward: \t286.43 Ploss: \t20.70978546142578 Floss: \t-20.7879581451416 Closs: \t4.308165080146864e-05 Mloss: \t0.00019986538973171264\n",
      "Total T:150000 Episode: \t149 Total Reward: \t353.20 Ploss: \t81.05764770507812 Floss: \t-80.8070068359375 Closs: \t3.944003765354864e-05 Mloss: \t0.0002096865209750831\n",
      "Total T:151000 Episode: \t150 Total Reward: \t340.52 Ploss: \t57.96380615234375 Floss: \t-56.94269561767578 Closs: \t3.911062958650291e-05 Mloss: \t0.00020964072609785944\n",
      "Ploss 57.96380615234375\n",
      "Floss -56.94269561767578\n",
      "Total reward: 3235.5170363968173\n",
      "Best achieved reward: 374.2992722191444\n",
      "--------------------------------\n",
      "Total T:152000 Episode: \t151 Total Reward: \t291.74 Ploss: \t97.50045776367188 Floss: \t-99.15911102294922 Closs: \t4.381933104014024e-05 Mloss: \t0.0002193399122916162\n",
      "Total T:153000 Episode: \t152 Total Reward: \t278.52 Ploss: \t87.29761505126953 Floss: \t-87.61730194091797 Closs: \t3.9193993870867416e-05 Mloss: \t0.00021700597426388413\n",
      "Total T:154000 Episode: \t153 Total Reward: \t468.55 Ploss: \t17.17447280883789 Floss: \t-17.2945499420166 Closs: \t4.088100104127079e-05 Mloss: \t0.00021447364997584373\n",
      "Total T:155000 Episode: \t154 Total Reward: \t409.79 Ploss: \t88.06990814208984 Floss: \t-88.46907043457031 Closs: \t4.801945760846138e-05 Mloss: \t0.00020624930039048195\n",
      "Total T:156000 Episode: \t155 Total Reward: \t423.34 Ploss: \t79.3045883178711 Floss: \t-79.06940460205078 Closs: \t3.6996876588091254e-05 Mloss: \t0.00019962986698374152\n",
      "Total T:157000 Episode: \t156 Total Reward: \t481.43 Ploss: \t51.32453918457031 Floss: \t-52.00275421142578 Closs: \t4.038131737615913e-05 Mloss: \t0.00019646456348709762\n",
      "Total T:158000 Episode: \t157 Total Reward: \t303.32 Ploss: \t59.8575553894043 Floss: \t-60.340965270996094 Closs: \t4.442902354639955e-05 Mloss: \t0.0002097488904837519\n",
      "Total T:159000 Episode: \t158 Total Reward: \t449.27 Ploss: \t27.72760772705078 Floss: \t-28.41362190246582 Closs: \t3.779605322051793e-05 Mloss: \t0.00020370596030261368\n",
      "Total T:160000 Episode: \t159 Total Reward: \t453.67 Ploss: \t138.29156494140625 Floss: \t-137.57717895507812 Closs: \t3.8427930121542886e-05 Mloss: \t0.0002070638001896441\n",
      "Total T:161000 Episode: \t160 Total Reward: \t317.20 Ploss: \t75.29811096191406 Floss: \t-75.55923461914062 Closs: \t4.391379115986638e-05 Mloss: \t0.00019820613670162857\n",
      "Total T:162000 Episode: \t161 Total Reward: \t316.76 Ploss: \t101.12466430664062 Floss: \t-101.9124984741211 Closs: \t3.929802551283501e-05 Mloss: \t0.00020043800759594887\n",
      "Total T:163000 Episode: \t162 Total Reward: \t335.65 Ploss: \t-22.615018844604492 Floss: \t22.878202438354492 Closs: \t3.522924453136511e-05 Mloss: \t0.00020139339903835207\n",
      "Total T:164000 Episode: \t163 Total Reward: \t319.77 Ploss: \t38.240291595458984 Floss: \t-37.99509811401367 Closs: \t4.136815186939202e-05 Mloss: \t0.00022042983619030565\n",
      "Total T:165000 Episode: \t164 Total Reward: \t300.64 Ploss: \t95.31485748291016 Floss: \t-95.04373168945312 Closs: \t4.2871608457062393e-05 Mloss: \t0.00019669528410304338\n",
      "Total T:166000 Episode: \t165 Total Reward: \t291.85 Ploss: \t71.95976257324219 Floss: \t-71.95368957519531 Closs: \t3.358349931659177e-05 Mloss: \t0.0002032368938671425\n",
      "Total T:167000 Episode: \t166 Total Reward: \t417.84 Ploss: \t80.59477996826172 Floss: \t-81.35774993896484 Closs: \t3.983129499829374e-05 Mloss: \t0.0002055928489426151\n",
      "Total T:168000 Episode: \t167 Total Reward: \t258.50 Ploss: \t147.23614501953125 Floss: \t-146.5060577392578 Closs: \t3.4939395845867693e-05 Mloss: \t0.000199243106180802\n",
      "Total T:169000 Episode: \t168 Total Reward: \t371.22 Ploss: \t34.83677673339844 Floss: \t-33.96402359008789 Closs: \t4.488553895498626e-05 Mloss: \t0.00019048800459131598\n",
      "Total T:170000 Episode: \t169 Total Reward: \t315.67 Ploss: \t89.96056365966797 Floss: \t-90.34040832519531 Closs: \t3.5148608731105924e-05 Mloss: \t0.0002047642774414271\n",
      "Total T:171000 Episode: \t170 Total Reward: \t372.76 Ploss: \t81.27616882324219 Floss: \t-80.84615325927734 Closs: \t3.510496026137844e-05 Mloss: \t0.00020897208014503121\n",
      "Total T:172000 Episode: \t171 Total Reward: \t390.96 Ploss: \t207.12554931640625 Floss: \t-207.6761474609375 Closs: \t3.974567516706884e-05 Mloss: \t0.00020726167713291943\n",
      "Total T:173000 Episode: \t172 Total Reward: \t314.23 Ploss: \t-1.1486132144927979 Floss: \t0.74365234375 Closs: \t3.933134939870797e-05 Mloss: \t0.00019010581308975816\n",
      "Total T:174000 Episode: \t173 Total Reward: \t311.42 Ploss: \t62.48497772216797 Floss: \t-61.53794860839844 Closs: \t3.725864735315554e-05 Mloss: \t0.00020993358339183033\n",
      "Total T:175000 Episode: \t174 Total Reward: \t328.79 Ploss: \t149.30384826660156 Floss: \t-148.9706268310547 Closs: \t3.6577286664396524e-05 Mloss: \t0.00020103532006032765\n",
      "Total T:176000 Episode: \t175 Total Reward: \t484.10 Ploss: \t160.48861694335938 Floss: \t-160.02099609375 Closs: \t3.906636993633583e-05 Mloss: \t0.00019789912039414048\n",
      "Total T:177000 Episode: \t176 Total Reward: \t376.27 Ploss: \t132.07839965820312 Floss: \t-132.89706420898438 Closs: \t3.568570900824852e-05 Mloss: \t0.0001989390148082748\n",
      "Total T:178000 Episode: \t177 Total Reward: \t357.30 Ploss: \t151.99948120117188 Floss: \t-152.20089721679688 Closs: \t3.649621066870168e-05 Mloss: \t0.00021105731138959527\n",
      "Total T:179000 Episode: \t178 Total Reward: \t341.91 Ploss: \t170.94268798828125 Floss: \t-172.66275024414062 Closs: \t3.472367825452238e-05 Mloss: \t0.00018817059753928334\n",
      "Total T:180000 Episode: \t179 Total Reward: \t343.79 Ploss: \t111.85118865966797 Floss: \t-112.8890380859375 Closs: \t3.914898115908727e-05 Mloss: \t0.00020219539874233305\n",
      "Total T:181000 Episode: \t180 Total Reward: \t350.52 Ploss: \t86.37944793701172 Floss: \t-85.15618896484375 Closs: \t3.4808686905307695e-05 Mloss: \t0.00020023541583213955\n",
      "Total T:182000 Episode: \t181 Total Reward: \t369.29 Ploss: \t50.88984298706055 Floss: \t-50.15103530883789 Closs: \t3.4834854886867106e-05 Mloss: \t0.0001969407603610307\n",
      "Total T:183000 Episode: \t182 Total Reward: \t325.76 Ploss: \t48.05910110473633 Floss: \t-48.24556350708008 Closs: \t3.674863910418935e-05 Mloss: \t0.00018755230121314526\n",
      "Total T:184000 Episode: \t183 Total Reward: \t358.95 Ploss: \t152.6727752685547 Floss: \t-151.9802703857422 Closs: \t3.864316386170685e-05 Mloss: \t0.00020096186199225485\n",
      "Total T:185000 Episode: \t184 Total Reward: \t269.60 Ploss: \t125.88868713378906 Floss: \t-129.10121154785156 Closs: \t3.782441854127683e-05 Mloss: \t0.00019213053747080266\n",
      "Total T:186000 Episode: \t185 Total Reward: \t438.63 Ploss: \t132.0790252685547 Floss: \t-132.95872497558594 Closs: \t3.441433364059776e-05 Mloss: \t0.00019955796597059816\n",
      "Total T:187000 Episode: \t186 Total Reward: \t359.70 Ploss: \t56.63193130493164 Floss: \t-56.16714859008789 Closs: \t3.397300315555185e-05 Mloss: \t0.00019331611110828817\n",
      "Total T:188000 Episode: \t187 Total Reward: \t387.35 Ploss: \t260.2027893066406 Floss: \t-259.034423828125 Closs: \t3.475473931757733e-05 Mloss: \t0.000206597542273812\n",
      "Total T:189000 Episode: \t188 Total Reward: \t434.42 Ploss: \t262.41485595703125 Floss: \t-262.40728759765625 Closs: \t4.2600011511240155e-05 Mloss: \t0.00019018036255147308\n",
      "Total T:190000 Episode: \t189 Total Reward: \t286.08 Ploss: \t234.19595336914062 Floss: \t-235.17320251464844 Closs: \t3.263027247157879e-05 Mloss: \t0.0002148301136912778\n",
      "Total T:191000 Episode: \t190 Total Reward: \t305.10 Ploss: \t84.56277465820312 Floss: \t-84.6146469116211 Closs: \t3.4411037631798536e-05 Mloss: \t0.00018942629685625434\n",
      "Total T:192000 Episode: \t191 Total Reward: \t385.13 Ploss: \t41.7849006652832 Floss: \t-41.26589584350586 Closs: \t3.689808363560587e-05 Mloss: \t0.00018808450840879232\n",
      "Total T:193000 Episode: \t192 Total Reward: \t514.78 Ploss: \t150.03123474121094 Floss: \t-150.16729736328125 Closs: \t3.7913061532890424e-05 Mloss: \t0.00019787508063018322\n",
      "Total T:194000 Episode: \t193 Total Reward: \t276.56 Ploss: \t25.853750228881836 Floss: \t-24.72085952758789 Closs: \t3.156183083774522e-05 Mloss: \t0.00018314595217816532\n",
      "Total T:195000 Episode: \t194 Total Reward: \t324.14 Ploss: \t-138.0299530029297 Floss: \t138.35269165039062 Closs: \t3.7352696381276473e-05 Mloss: \t0.0001962799724424258\n",
      "Total T:196000 Episode: \t195 Total Reward: \t326.32 Ploss: \t60.52661895751953 Floss: \t-63.13816452026367 Closs: \t3.7288173189153895e-05 Mloss: \t0.00020687721553258598\n",
      "Total T:197000 Episode: \t196 Total Reward: \t317.47 Ploss: \t320.0023193359375 Floss: \t-320.47479248046875 Closs: \t3.144394213450141e-05 Mloss: \t0.00019252620404586196\n",
      "Total T:198000 Episode: \t197 Total Reward: \t362.97 Ploss: \t150.62680053710938 Floss: \t-149.79493713378906 Closs: \t3.6669403925770894e-05 Mloss: \t0.00018019643903244287\n",
      "Total T:199000 Episode: \t198 Total Reward: \t386.91 Ploss: \t424.8737487792969 Floss: \t-423.7244873046875 Closs: \t3.7637673813151196e-05 Mloss: \t0.00019554620666895062\n",
      "Total T:200000 Episode: \t199 Total Reward: \t295.61 Ploss: \t208.16050720214844 Floss: \t-208.40687561035156 Closs: \t3.463075699983165e-05 Mloss: \t0.00019865987997036427\n",
      "Total T:201000 Episode: \t200 Total Reward: \t308.51 Ploss: \t186.7411651611328 Floss: \t-187.89503479003906 Closs: \t3.1711508199805394e-05 Mloss: \t0.00017935298092197627\n",
      "Ploss 186.7411651611328\n",
      "Floss -187.89503479003906\n",
      "Total reward: 3253.9343972704664\n",
      "Best achieved reward: 387.80451410956465\n",
      "--------------------------------\n",
      "Total T:202000 Episode: \t201 Total Reward: \t269.89 Ploss: \t249.1522216796875 Floss: \t-249.44842529296875 Closs: \t4.207819438306615e-05 Mloss: \t0.00018558530427981168\n",
      "Total T:203000 Episode: \t202 Total Reward: \t449.07 Ploss: \t288.50311279296875 Floss: \t-288.0395202636719 Closs: \t2.9430766517180018e-05 Mloss: \t0.00018088800425175577\n",
      "Total T:204000 Episode: \t203 Total Reward: \t352.57 Ploss: \t121.51499938964844 Floss: \t-120.05113220214844 Closs: \t3.4951790439663455e-05 Mloss: \t0.00017962213314604014\n",
      "Total T:205000 Episode: \t204 Total Reward: \t493.20 Ploss: \t426.665771484375 Floss: \t-427.52008056640625 Closs: \t3.567590465536341e-05 Mloss: \t0.0001903541706269607\n",
      "Total T:206000 Episode: \t205 Total Reward: \t519.53 Ploss: \t119.99652099609375 Floss: \t-121.20738220214844 Closs: \t4.319312938605435e-05 Mloss: \t0.00017832720186561346\n",
      "Total T:207000 Episode: \t206 Total Reward: \t389.91 Ploss: \t233.33460998535156 Floss: \t-232.03268432617188 Closs: \t3.069615922868252e-05 Mloss: \t0.00017689455125946552\n",
      "Total T:208000 Episode: \t207 Total Reward: \t391.58 Ploss: \t305.5181884765625 Floss: \t-307.53436279296875 Closs: \t3.6405410355655476e-05 Mloss: \t0.0001854704023571685\n",
      "Total T:209000 Episode: \t208 Total Reward: \t521.71 Ploss: \t38.2861328125 Floss: \t-38.66257858276367 Closs: \t3.544325227267109e-05 Mloss: \t0.00017208087956532836\n",
      "Total T:210000 Episode: \t209 Total Reward: \t321.64 Ploss: \t291.6291198730469 Floss: \t-292.35589599609375 Closs: \t3.673943501780741e-05 Mloss: \t0.00017341345665045083\n",
      "Total T:211000 Episode: \t210 Total Reward: \t483.73 Ploss: \t297.5467834472656 Floss: \t-295.9013671875 Closs: \t3.4667598811211064e-05 Mloss: \t0.00017954807844944298\n",
      "Total T:212000 Episode: \t211 Total Reward: \t448.70 Ploss: \t185.67050170898438 Floss: \t-185.45941162109375 Closs: \t2.9893924875068478e-05 Mloss: \t0.00015953760885167867\n",
      "Total T:213000 Episode: \t212 Total Reward: \t498.63 Ploss: \t137.95828247070312 Floss: \t-137.68585205078125 Closs: \t3.94891612813808e-05 Mloss: \t0.00017637156997807324\n",
      "Total T:214000 Episode: \t213 Total Reward: \t377.78 Ploss: \t250.52757263183594 Floss: \t-250.75042724609375 Closs: \t3.20828148687724e-05 Mloss: \t0.000166076555615291\n",
      "Total T:215000 Episode: \t214 Total Reward: \t301.05 Ploss: \t366.2752990722656 Floss: \t-366.16412353515625 Closs: \t3.2904201361816376e-05 Mloss: \t0.00017002840468194336\n",
      "Total T:216000 Episode: \t215 Total Reward: \t337.39 Ploss: \t102.0057373046875 Floss: \t-102.39800262451172 Closs: \t3.563721475074999e-05 Mloss: \t0.00016421002510469407\n",
      "Total T:217000 Episode: \t216 Total Reward: \t331.22 Ploss: \t155.93402099609375 Floss: \t-157.36460876464844 Closs: \t3.331481639179401e-05 Mloss: \t0.00016504505765624344\n",
      "Total T:218000 Episode: \t217 Total Reward: \t526.74 Ploss: \t487.8375549316406 Floss: \t-485.7553405761719 Closs: \t3.2313713745679706e-05 Mloss: \t0.00015418700058944523\n",
      "Total T:219000 Episode: \t218 Total Reward: \t437.57 Ploss: \t48.09613037109375 Floss: \t-48.922733306884766 Closs: \t3.283845217083581e-05 Mloss: \t0.00016770265938248485\n",
      "Total T:220000 Episode: \t219 Total Reward: \t365.29 Ploss: \t436.7989807128906 Floss: \t-439.60699462890625 Closs: \t3.6503359297057614e-05 Mloss: \t0.00015815682127140462\n",
      "Total T:221000 Episode: \t220 Total Reward: \t421.45 Ploss: \t89.1303482055664 Floss: \t-87.95484161376953 Closs: \t2.769355160125997e-05 Mloss: \t0.00016172903997357935\n",
      "Total T:222000 Episode: \t221 Total Reward: \t318.10 Ploss: \t354.1304626464844 Floss: \t-357.95404052734375 Closs: \t3.556525189196691e-05 Mloss: \t0.00015717369387857616\n",
      "Total T:223000 Episode: \t222 Total Reward: \t310.72 Ploss: \t309.7937316894531 Floss: \t-313.51531982421875 Closs: \t3.4182947274530306e-05 Mloss: \t0.00015319057274609804\n",
      "Total T:224000 Episode: \t223 Total Reward: \t463.86 Ploss: \t76.37261199951172 Floss: \t-81.29066467285156 Closs: \t2.970979767269455e-05 Mloss: \t0.0001542580284876749\n",
      "Total T:225000 Episode: \t224 Total Reward: \t383.36 Ploss: \t172.7822265625 Floss: \t-174.26101684570312 Closs: \t3.304046913399361e-05 Mloss: \t0.0001458363694837317\n",
      "Total T:226000 Episode: \t225 Total Reward: \t478.96 Ploss: \t309.18890380859375 Floss: \t-310.3171691894531 Closs: \t2.8897875381517224e-05 Mloss: \t0.0001559712109155953\n",
      "Total T:227000 Episode: \t226 Total Reward: \t377.32 Ploss: \t-55.666561126708984 Floss: \t55.45585632324219 Closs: \t3.385854870430194e-05 Mloss: \t0.00015541807806584984\n",
      "Total T:228000 Episode: \t227 Total Reward: \t367.71 Ploss: \t443.5108642578125 Floss: \t-440.7796325683594 Closs: \t3.7342360883485526e-05 Mloss: \t0.00015694694593548775\n",
      "Total T:229000 Episode: \t228 Total Reward: \t347.81 Ploss: \t277.55902099609375 Floss: \t-276.8308410644531 Closs: \t3.322576958453283e-05 Mloss: \t0.0001432017597835511\n",
      "Total T:230000 Episode: \t229 Total Reward: \t373.67 Ploss: \t501.86163330078125 Floss: \t-501.7479553222656 Closs: \t2.859125925169792e-05 Mloss: \t0.00015597627498209476\n",
      "Total T:231000 Episode: \t230 Total Reward: \t290.68 Ploss: \t663.3165283203125 Floss: \t-661.3794555664062 Closs: \t3.155530066578649e-05 Mloss: \t0.00015687625273130834\n",
      "Total T:232000 Episode: \t231 Total Reward: \t361.64 Ploss: \t403.20111083984375 Floss: \t-401.5850830078125 Closs: \t2.9569493563030846e-05 Mloss: \t0.00015237242041621357\n",
      "Total T:233000 Episode: \t232 Total Reward: \t313.47 Ploss: \t243.80416870117188 Floss: \t-243.61265563964844 Closs: \t3.0237973987823352e-05 Mloss: \t0.00013994656910654157\n",
      "Total T:234000 Episode: \t233 Total Reward: \t332.31 Ploss: \t41.57015609741211 Floss: \t-42.88796615600586 Closs: \t3.13498530886136e-05 Mloss: \t0.00014513806672766805\n",
      "Total T:235000 Episode: \t234 Total Reward: \t356.47 Ploss: \t321.159912109375 Floss: \t-321.9855651855469 Closs: \t3.4124081139452755e-05 Mloss: \t0.00015459494898095727\n",
      "Total T:236000 Episode: \t235 Total Reward: \t369.10 Ploss: \t543.7962646484375 Floss: \t-545.3606567382812 Closs: \t2.9455954063450918e-05 Mloss: \t0.0001485770189901814\n",
      "Total T:237000 Episode: \t236 Total Reward: \t370.39 Ploss: \t184.10562133789062 Floss: \t-183.0780792236328 Closs: \t2.8715970984194428e-05 Mloss: \t0.00015196579624898732\n",
      "Total T:238000 Episode: \t237 Total Reward: \t330.88 Ploss: \t480.30865478515625 Floss: \t-481.2764587402344 Closs: \t2.9669783543795347e-05 Mloss: \t0.00015371105109807104\n",
      "Total T:239000 Episode: \t238 Total Reward: \t293.58 Ploss: \t250.85617065429688 Floss: \t-254.85675048828125 Closs: \t2.958682853204664e-05 Mloss: \t0.0001473704178351909\n",
      "Total T:240000 Episode: \t239 Total Reward: \t343.67 Ploss: \t3.7406249046325684 Floss: \t-4.788593769073486 Closs: \t3.333041968289763e-05 Mloss: \t0.00014459081285167485\n",
      "Total T:241000 Episode: \t240 Total Reward: \t333.00 Ploss: \t242.9058074951172 Floss: \t-244.79592895507812 Closs: \t2.8985796234337613e-05 Mloss: \t0.00014504676801152527\n",
      "Total T:242000 Episode: \t241 Total Reward: \t323.39 Ploss: \t561.6981811523438 Floss: \t-565.5023803710938 Closs: \t3.04061559290858e-05 Mloss: \t0.00014795447350479662\n",
      "Total T:243000 Episode: \t242 Total Reward: \t508.90 Ploss: \t731.3468017578125 Floss: \t-726.77880859375 Closs: \t2.8221127649885602e-05 Mloss: \t0.0001507366105215624\n",
      "Total T:244000 Episode: \t243 Total Reward: \t479.36 Ploss: \t486.9209289550781 Floss: \t-487.52764892578125 Closs: \t3.684738840092905e-05 Mloss: \t0.00014730959082953632\n",
      "Total T:245000 Episode: \t244 Total Reward: \t328.58 Ploss: \t487.67919921875 Floss: \t-488.56396484375 Closs: \t2.7104821128887124e-05 Mloss: \t0.00015067348431330174\n",
      "Total T:246000 Episode: \t245 Total Reward: \t570.35 Ploss: \t367.5249938964844 Floss: \t-364.71319580078125 Closs: \t2.7789390514953993e-05 Mloss: \t0.00014396461483556777\n",
      "Total T:247000 Episode: \t246 Total Reward: \t349.02 Ploss: \t381.8082580566406 Floss: \t-377.812255859375 Closs: \t3.1389376090373844e-05 Mloss: \t0.0001495037431595847\n",
      "Total T:248000 Episode: \t247 Total Reward: \t279.19 Ploss: \t672.8392333984375 Floss: \t-672.3740234375 Closs: \t2.6851746952161193e-05 Mloss: \t0.0001423267094651237\n",
      "Total T:249000 Episode: \t248 Total Reward: \t374.93 Ploss: \t733.6253662109375 Floss: \t-734.8171997070312 Closs: \t2.9332486519706436e-05 Mloss: \t0.00014543486759066582\n",
      "Total T:250000 Episode: \t249 Total Reward: \t473.42 Ploss: \t463.04302978515625 Floss: \t-465.00811767578125 Closs: \t3.017738890775945e-05 Mloss: \t0.00014711137919221073\n",
      "Total T:251000 Episode: \t250 Total Reward: \t315.76 Ploss: \t-91.8699951171875 Floss: \t89.03241729736328 Closs: \t2.9610619094455615e-05 Mloss: \t0.00015233398880809546\n",
      "Ploss -91.8699951171875\n",
      "Floss 89.03241729736328\n",
      "Total reward: 4770.8164367092795\n",
      "Best achieved reward: 595.6377427238093\n",
      "--------------------------------\n",
      "Total T:252000 Episode: \t251 Total Reward: \t416.01 Ploss: \t129.1629638671875 Floss: \t-132.74952697753906 Closs: \t2.931673043349292e-05 Mloss: \t0.00015312778123188764\n",
      "Total T:253000 Episode: \t252 Total Reward: \t229.91 Ploss: \t155.28428649902344 Floss: \t-157.47874450683594 Closs: \t3.108131204498932e-05 Mloss: \t0.0001463056105421856\n",
      "Total T:254000 Episode: \t253 Total Reward: \t476.84 Ploss: \t-573.3735961914062 Floss: \t573.198486328125 Closs: \t2.608285467431415e-05 Mloss: \t0.00014485952851828188\n",
      "Total T:255000 Episode: \t254 Total Reward: \t367.58 Ploss: \t536.2006225585938 Floss: \t-534.8742065429688 Closs: \t3.0315666663227603e-05 Mloss: \t0.00013751712685916573\n",
      "Total T:256000 Episode: \t255 Total Reward: \t399.80 Ploss: \t1001.322998046875 Floss: \t-1003.741455078125 Closs: \t2.8564689273480326e-05 Mloss: \t0.00014110526535660028\n",
      "Total T:257000 Episode: \t256 Total Reward: \t343.13 Ploss: \t639.9571533203125 Floss: \t-642.98388671875 Closs: \t3.247828863095492e-05 Mloss: \t0.00014328141696751118\n",
      "Total T:258000 Episode: \t257 Total Reward: \t337.45 Ploss: \t313.51177978515625 Floss: \t-309.34771728515625 Closs: \t2.782943738566246e-05 Mloss: \t0.00014157498662825674\n",
      "Total T:259000 Episode: \t258 Total Reward: \t417.79 Ploss: \t317.2440490722656 Floss: \t-314.5892028808594 Closs: \t2.7587415388552472e-05 Mloss: \t0.0001437562459614128\n",
      "Total T:260000 Episode: \t259 Total Reward: \t288.11 Ploss: \t938.9352416992188 Floss: \t-940.9765625 Closs: \t2.5788243874558248e-05 Mloss: \t0.0001471861614845693\n",
      "Total T:261000 Episode: \t260 Total Reward: \t317.21 Ploss: \t14.182108879089355 Floss: \t-7.604296684265137 Closs: \t3.348188693053089e-05 Mloss: \t0.00014677290164399892\n",
      "Total T:262000 Episode: \t261 Total Reward: \t346.78 Ploss: \t170.1710968017578 Floss: \t-165.76226806640625 Closs: \t2.3502490876126103e-05 Mloss: \t0.00013622768165078014\n",
      "Total T:263000 Episode: \t262 Total Reward: \t326.59 Ploss: \t-246.046875 Floss: \t246.5313262939453 Closs: \t3.049420593015384e-05 Mloss: \t0.00013445808144751936\n",
      "Total T:264000 Episode: \t263 Total Reward: \t333.26 Ploss: \t125.08406066894531 Floss: \t-123.72483825683594 Closs: \t2.6086187062901445e-05 Mloss: \t0.00014229252701625228\n",
      "Total T:265000 Episode: \t264 Total Reward: \t487.68 Ploss: \t346.79913330078125 Floss: \t-349.7485046386719 Closs: \t3.269354419899173e-05 Mloss: \t0.0001349670928902924\n",
      "Total T:266000 Episode: \t265 Total Reward: \t393.10 Ploss: \t676.0781860351562 Floss: \t-673.0413818359375 Closs: \t2.433015833958052e-05 Mloss: \t0.00014343144721351564\n",
      "Total T:267000 Episode: \t266 Total Reward: \t459.95 Ploss: \t606.6686401367188 Floss: \t-607.497314453125 Closs: \t2.9639366402989253e-05 Mloss: \t0.0001450296986149624\n",
      "Total T:268000 Episode: \t267 Total Reward: \t390.34 Ploss: \t142.91140747070312 Floss: \t-145.24789428710938 Closs: \t2.7509671781444922e-05 Mloss: \t0.00014462224498856813\n",
      "Total T:269000 Episode: \t268 Total Reward: \t346.95 Ploss: \t610.4177856445312 Floss: \t-612.9607543945312 Closs: \t3.060744347749278e-05 Mloss: \t0.00014711545372847468\n",
      "Total T:270000 Episode: \t269 Total Reward: \t289.60 Ploss: \t638.9428100585938 Floss: \t-641.1778564453125 Closs: \t2.6189081836491823e-05 Mloss: \t0.00013091402070131153\n",
      "Total T:271000 Episode: \t270 Total Reward: \t424.94 Ploss: \t84.69601440429688 Floss: \t-83.15789031982422 Closs: \t2.6230651201331057e-05 Mloss: \t0.0001439529296476394\n",
      "Total T:272000 Episode: \t271 Total Reward: \t325.22 Ploss: \t525.254150390625 Floss: \t-522.2984008789062 Closs: \t2.9270306185935624e-05 Mloss: \t0.00014131228090263903\n",
      "Total T:273000 Episode: \t272 Total Reward: \t415.85 Ploss: \t-128.7421875 Floss: \t127.98812103271484 Closs: \t3.0353756301337853e-05 Mloss: \t0.000136399467010051\n",
      "Total T:274000 Episode: \t273 Total Reward: \t379.17 Ploss: \t995.5985107421875 Floss: \t-1004.4138793945312 Closs: \t2.5334273232147098e-05 Mloss: \t0.00013810911332257092\n",
      "Total T:275000 Episode: \t274 Total Reward: \t416.98 Ploss: \t701.3142700195312 Floss: \t-703.8461303710938 Closs: \t2.3858628992456943e-05 Mloss: \t0.00013745513570029289\n",
      "Total T:276000 Episode: \t275 Total Reward: \t418.35 Ploss: \t363.2799072265625 Floss: \t-363.9822692871094 Closs: \t3.132829078822397e-05 Mloss: \t0.00013855467841494828\n",
      "Total T:277000 Episode: \t276 Total Reward: \t381.64 Ploss: \t671.7079467773438 Floss: \t-669.4727783203125 Closs: \t2.5335395548609085e-05 Mloss: \t0.00014157468103803694\n",
      "Total T:278000 Episode: \t277 Total Reward: \t573.58 Ploss: \t773.8180541992188 Floss: \t-779.6734008789062 Closs: \t3.1469746318180114e-05 Mloss: \t0.00014010525774210691\n",
      "Total T:279000 Episode: \t278 Total Reward: \t455.50 Ploss: \t679.4453125 Floss: \t-682.4682006835938 Closs: \t2.1583735360763967e-05 Mloss: \t0.00013409371604211628\n",
      "Total T:280000 Episode: \t279 Total Reward: \t388.42 Ploss: \t552.8125 Floss: \t-554.610595703125 Closs: \t2.775438224489335e-05 Mloss: \t0.0001403026544721797\n",
      "Total T:281000 Episode: \t280 Total Reward: \t381.31 Ploss: \t-184.0399169921875 Floss: \t176.2891387939453 Closs: \t2.7246900572208688e-05 Mloss: \t0.00014110772463027388\n",
      "Total T:282000 Episode: \t281 Total Reward: \t235.27 Ploss: \t403.9557800292969 Floss: \t-400.66436767578125 Closs: \t2.6951520339935087e-05 Mloss: \t0.00013369008956942707\n",
      "Total T:283000 Episode: \t282 Total Reward: \t352.88 Ploss: \t1595.284912109375 Floss: \t-1595.7734375 Closs: \t2.526658499846235e-05 Mloss: \t0.00013465330994222313\n",
      "Total T:284000 Episode: \t283 Total Reward: \t333.59 Ploss: \t713.2291870117188 Floss: \t-715.504150390625 Closs: \t2.7118370780954137e-05 Mloss: \t0.00014096232189331204\n",
      "Total T:285000 Episode: \t284 Total Reward: \t352.39 Ploss: \t539.6179809570312 Floss: \t-545.681396484375 Closs: \t2.798260175040923e-05 Mloss: \t0.00013418684829957783\n",
      "Total T:286000 Episode: \t285 Total Reward: \t329.66 Ploss: \t1088.7578125 Floss: \t-1087.8262939453125 Closs: \t2.5503937649773434e-05 Mloss: \t0.0001413391000824049\n",
      "Total T:287000 Episode: \t286 Total Reward: \t400.82 Ploss: \t-34.68585968017578 Floss: \t34.060935974121094 Closs: \t2.605352710816078e-05 Mloss: \t0.00013797255815006793\n",
      "Total T:288000 Episode: \t287 Total Reward: \t235.16 Ploss: \t171.60694885253906 Floss: \t-170.39889526367188 Closs: \t2.6734969651442952e-05 Mloss: \t0.00012946211791131645\n",
      "Total T:289000 Episode: \t288 Total Reward: \t430.24 Ploss: \t654.7858276367188 Floss: \t-654.9161376953125 Closs: \t2.4114651751006022e-05 Mloss: \t0.00013572040188591927\n",
      "Total T:290000 Episode: \t289 Total Reward: \t480.61 Ploss: \t-279.0302429199219 Floss: \t275.22906494140625 Closs: \t2.8398804715834558e-05 Mloss: \t0.00013957053306512535\n",
      "Total T:291000 Episode: \t290 Total Reward: \t398.55 Ploss: \t1423.9854736328125 Floss: \t-1427.349365234375 Closs: \t2.4767572540440597e-05 Mloss: \t0.00014518028183374554\n",
      "Total T:292000 Episode: \t291 Total Reward: \t352.46 Ploss: \t325.2957763671875 Floss: \t-326.77569580078125 Closs: \t2.7928954295930453e-05 Mloss: \t0.00014141864085104316\n",
      "Total T:293000 Episode: \t292 Total Reward: \t348.55 Ploss: \t900.4674682617188 Floss: \t-898.4275512695312 Closs: \t2.4187052986235358e-05 Mloss: \t0.00013385772763285786\n",
      "Total T:294000 Episode: \t293 Total Reward: \t369.14 Ploss: \t596.4154052734375 Floss: \t-596.3900146484375 Closs: \t2.660120117070619e-05 Mloss: \t0.00013443724310491234\n",
      "Total T:295000 Episode: \t294 Total Reward: \t322.90 Ploss: \t227.9137420654297 Floss: \t-226.511474609375 Closs: \t2.9909708246123046e-05 Mloss: \t0.00012738200894091278\n",
      "Total T:296000 Episode: \t295 Total Reward: \t388.96 Ploss: \t396.72296142578125 Floss: \t-395.521240234375 Closs: \t2.3190450519905426e-05 Mloss: \t0.00013442293857224286\n",
      "Total T:297000 Episode: \t296 Total Reward: \t426.69 Ploss: \t1406.31640625 Floss: \t-1410.98388671875 Closs: \t2.2595369955524802e-05 Mloss: \t0.00012099887680960819\n",
      "Total T:298000 Episode: \t297 Total Reward: \t365.28 Ploss: \t354.0167236328125 Floss: \t-343.8014831542969 Closs: \t2.3508420781581663e-05 Mloss: \t0.00013419978495221585\n",
      "Total T:299000 Episode: \t298 Total Reward: \t413.46 Ploss: \t998.3851318359375 Floss: \t-1005.8536987304688 Closs: \t2.8187758289277554e-05 Mloss: \t0.00013659887190442532\n",
      "Total T:300000 Episode: \t299 Total Reward: \t333.55 Ploss: \t228.09678649902344 Floss: \t-231.6082000732422 Closs: \t2.47109910560539e-05 Mloss: \t0.00012747767323162407\n",
      "Total T:301000 Episode: \t300 Total Reward: \t397.83 Ploss: \t680.5126342773438 Floss: \t-677.5863647460938 Closs: \t2.630248673085589e-05 Mloss: \t0.0001352918625343591\n",
      "Ploss 680.5126342773438\n",
      "Floss -677.5863647460938\n",
      "Total reward: 3265.70309107633\n",
      "Best achieved reward: 365.99695600274595\n",
      "--------------------------------\n",
      "Total T:302000 Episode: \t301 Total Reward: \t365.50 Ploss: \t458.27764892578125 Floss: \t-457.2887268066406 Closs: \t2.4122153263306245e-05 Mloss: \t0.0001280171563848853\n",
      "Total T:303000 Episode: \t302 Total Reward: \t361.48 Ploss: \t425.7795104980469 Floss: \t-416.6802978515625 Closs: \t2.5938763428712264e-05 Mloss: \t0.0001307467755395919\n",
      "Total T:304000 Episode: \t303 Total Reward: \t442.11 Ploss: \t-227.251708984375 Floss: \t226.08078002929688 Closs: \t2.518418841646053e-05 Mloss: \t0.00013010954717174172\n",
      "Total T:305000 Episode: \t304 Total Reward: \t319.60 Ploss: \t438.306396484375 Floss: \t-444.6237487792969 Closs: \t2.4070763174677268e-05 Mloss: \t0.00012995726137887686\n",
      "Total T:306000 Episode: \t305 Total Reward: \t378.43 Ploss: \t591.7557983398438 Floss: \t-585.3015747070312 Closs: \t2.4761277018114924e-05 Mloss: \t0.00013769806537311524\n",
      "Total T:307000 Episode: \t306 Total Reward: \t397.93 Ploss: \t1201.83251953125 Floss: \t-1204.2662353515625 Closs: \t2.9122129490133375e-05 Mloss: \t0.00014066562289372087\n",
      "Total T:308000 Episode: \t307 Total Reward: \t192.76 Ploss: \t1165.473876953125 Floss: \t-1167.0013427734375 Closs: \t2.237028456875123e-05 Mloss: \t0.00012457463890314102\n",
      "Total T:309000 Episode: \t308 Total Reward: \t308.86 Ploss: \t1015.9807739257812 Floss: \t-1016.0974731445312 Closs: \t2.5615532649680972e-05 Mloss: \t0.00013177881191950291\n",
      "Total T:310000 Episode: \t309 Total Reward: \t397.29 Ploss: \t-146.90219116210938 Floss: \t148.1199951171875 Closs: \t2.4631630367366597e-05 Mloss: \t0.00012712605530396104\n",
      "Total T:311000 Episode: \t310 Total Reward: \t372.74 Ploss: \t262.8778076171875 Floss: \t-264.3990478515625 Closs: \t2.631230017868802e-05 Mloss: \t0.0001232842478202656\n",
      "Total T:312000 Episode: \t311 Total Reward: \t335.66 Ploss: \t1390.7154541015625 Floss: \t-1393.2786865234375 Closs: \t2.4947317797341384e-05 Mloss: \t0.00013730474165640771\n",
      "Total T:313000 Episode: \t312 Total Reward: \t310.64 Ploss: \t591.5257568359375 Floss: \t-592.099853515625 Closs: \t2.394836519670207e-05 Mloss: \t0.00013135490007698536\n",
      "Total T:314000 Episode: \t313 Total Reward: \t453.99 Ploss: \t1109.02734375 Floss: \t-1106.217041015625 Closs: \t2.4528217181796208e-05 Mloss: \t0.00012704833352472633\n",
      "Total T:315000 Episode: \t314 Total Reward: \t400.05 Ploss: \t261.64093017578125 Floss: \t-268.11639404296875 Closs: \t2.4297518393723294e-05 Mloss: \t0.00011910223111044616\n",
      "Total T:316000 Episode: \t315 Total Reward: \t299.80 Ploss: \t832.42138671875 Floss: \t-842.6004638671875 Closs: \t2.359531026741024e-05 Mloss: \t0.00013638385280501097\n"
     ]
    }
   ],
   "source": [
    "total_reward = 0\n",
    "total_step = 0\n",
    "best_reward = 0\n",
    "\n",
    "for episode in tqdm(range(max_episodes), position=0, leave=True):\n",
    "    state = env.reset()\n",
    "    for step in range(max_steps): \n",
    "        #action, ploss, floss = agent.update(state)\n",
    "        action = agent.select_action(state)  \n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        agent.replay_buffer.push((state, next_state, action, reward, np.float(done)))\n",
    "        \n",
    "        state = next_state\n",
    "        total_step+=1\n",
    "        total_reward +=reward\n",
    "        #_, ploss, floss = agent.update(None)\n",
    "        if done:\n",
    "            break\n",
    "    rewards.append(total_reward)\n",
    "    \n",
    "    _, ploss, floss = agent.update(None)\n",
    "    closs, mloss = agent.env_update()\n",
    "    \n",
    "    # _, ploss, floss = agent.update(None)\n",
    "    # if train_worldmodel:\n",
    "    #     agent.env_update()\n",
    "            \n",
    "    print(\"Total T:{} Episode: \\t{} Total Reward: \\t{:0.2f} Ploss: \\t{} Floss: \\t{} Closs: \\t{} Mloss: \\t{}\".format(total_step, episode, total_reward, Average(ploss).item(), Average(floss).item(), Average(closs).item(), Average(mloss).item()))\n",
    "    total_reward=0\n",
    "    if episode % 50 == 0:\n",
    "        print('Ploss', Average(ploss).item())\n",
    "        print('Floss', Average(floss).item())\n",
    "        achieved_reward = agent.evaluate(agent.policy, env)\n",
    "        if achieved_reward> best_reward:\n",
    "            best_reward = achieved_reward\n",
    "            torch.save(agent.policy.state_dict(), f'{model_directory}{policy_name}')\n",
    "        print(\"--------------------------------\")\n",
    "        gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374c60d-d97f-4661-a396-03f080fce330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "agent_name = f'{domain_name}_{task_name}_hs{model_hidden_size}_tanh_05'\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(agent_name, size=20)\n",
    "plt.xlabel(\"episodes\", size=20)\n",
    "plt.ylabel(\"rewards\", size=20)\n",
    "plt.plot(rewards[:250])\n",
    "plt.savefig(f'{plot_directory}{agent_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae0ff5-e8ad-4d36-871e-a7c82eb69aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be17e40-93d4-49a3-8066-cfd19e106cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d59ba1-6d59-49c1-805c-700902e88cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a07720-f8fe-4e5f-bb3c-4b51d531142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "agent_name = f'{domain_name}_{task_name}_hs{model_hidden_size}_tanh'\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(agent_name, size=20)\n",
    "plt.xlabel(\"episodes\", size=20)\n",
    "plt.ylabel(\"rewards\", size=20)\n",
    "plt.plot(rewards)\n",
    "plt.savefig(f'/home/jovyan/LinearProgrammingRL/plots/{agent_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747290db-a319-47cc-bf62-fbab0a5dabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "agent_name = f'{domain_name}_{task_name}_hs{model_hidden_size}_tanh'\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(agent_name, size=20)\n",
    "plt.xlabel(\"episodes\", size=20)\n",
    "plt.ylabel(\"rewards\", size=20)\n",
    "plt.plot(rewards)\n",
    "plt.savefig(f'/home/jovyan/LinearProgrammingRL/plots/{agent_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46dcaa-0e95-409c-83ba-667b1e57ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(agent_name, size=20)\n",
    "plt.xlabel(\"episodes\", size=20)\n",
    "plt.ylabel(\"rewards\", size=20)\n",
    "plt.plot(rewards)\n",
    "plt.savefig(f'/home/jovyan/LinearProgrammingRL/plots/{agent_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d560cf-9e6d-4bf1-a4e0-6a98d5410daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
